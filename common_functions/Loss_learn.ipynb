{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CrossEntropyLoss\n",
    "### class torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100, reduce=None, reduction='mean')[source]\n",
    "\n",
    "作用:\n",
    "\n",
    "- 针对单目标分类问题结合了 nn.LogSoftmax() 和 nn.NLLLoss() 来计算 loss.用于训练 C 类别classes 的分类问题.\n",
    "\n",
    "    - 参数 weight 是 1D Tensor, 分别对应每个类别class 的权重. 对于类别不平衡的训练数据集比较有用.\n",
    "\n",
    "    - 输入input 包含了每一类别的概率或score.\n",
    "\n",
    "    - 输入 input Tensor 的大小是 (minibatch,C) 或 (minibatch,C,d1,d2,...,dK). K≥2 表示 K-dim 场景.\n",
    "\n",
    "    - 输入 target 是类别class 的索引([0,C−1], C 是类别classes 总数.)\n",
    "\n",
    "    $loss(score,target)=-log(\\frac{exp(score[target])}{\\sum_{j}^{C}exp(score[j]])})=-score[target]+log(\\sum_{j}^{C}exp(score[j]))$\n",
    "    - 带 weight形式:\n",
    "    \n",
    "    $weight[target](-score[target]+log(\\sum_{j}^{C}exp(score[j])))$\n",
    "    - losses 在 minibatch 内求平均.\n",
    "\n",
    "- 也支持高维输入 inputs, 如 2D images, 则会逐元素计算 NLL Loss.\n",
    "\n",
    "参数：\n",
    "- weight(Tensor, optional) - 每个类别class 的权重. 默认为值为 1 的 Tensor.\n",
    "\n",
    "- size_average(bool, optional) – 默认为 True.\n",
    "\n",
    "    - size_average=True, 则 losses 在 minibatch 结合 weight 求平均average.\n",
    "\n",
    "    - size_average=False, 则losses 在 minibatch 求相加和sum.\n",
    "\n",
    "    - 当 reduce=False 时,忽略该参数.\n",
    "\n",
    "- ignore_index(int, optional) - 指定忽略的 target 值, 不影响 input 梯度计算.\n",
    "\n",
    "    - 当 size_average=True, 对所有非忽略的 targets 求平均.\n",
    "\n",
    "- reduce(bool, optional) - 不推荐使用，默认为 True.\n",
    "\n",
    "    - reduce=True, 则 losses 在 minibatch 求平均或相加和.\n",
    "\n",
    "    - reduce=False, 则 losses 返回 per batch 值, 并忽略 size_average.\n",
    "- reduction(string,optional) - \n",
    "    - reduction='none',逐个像素点求loss,输出的loss的size与target一致\n",
    "    - reduction='mean',默认，输出总和除以输出元素数量(batch_size)\n",
    "    - reduction='sum',输出求和\n",
    "\n",
    "输入:input x, (N,C), C=num_classes 类别总数。输入:target y, (N), 每个值都是 0≤targets[i]≤C−1\n",
    "输出:如果 reduce=True, 输出标量值. 如果 reduce=False, 输出与输入target一致, (N)(N)\n",
    "\n",
    "输入:input x, (N,C,d1,d2,...,dK)(N,C,d1,d2,...,dK), K≥2 适用于 K-dim 场景。输入: target y, (N,d1,d2,...,dK), K≥2适用于 K-dim 场景\n",
    "\n",
    "输出:如果 reduce=True, 输出标量值. 如果 reduce=False, 输出与输入target一致, (N,d1,d2,...,dK), K≥2 适用于 KK-dim 场景\n",
    "\n",
    "**注意：**size_average和reduce正在被弃用，指定size_average和reduction中的任何一个都将覆盖reduce。 默认值：'mean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[[[ 5.7864e-01,  6.5832e-01,  9.5113e-01, -1.7745e-01],\n",
      "          [-5.4101e-01, -1.3930e-01, -5.1329e-01,  7.7888e-01],\n",
      "          [-8.7849e-02, -2.2284e+00, -6.6949e-01, -9.2986e-01]],\n",
      "\n",
      "         [[ 6.8890e-01, -1.0171e+00,  9.6870e-01,  1.7296e-01],\n",
      "          [-6.8021e-01,  1.4829e+00, -7.4961e-01,  1.6926e+00],\n",
      "          [ 3.9351e-01,  1.0096e+00,  2.5396e-01,  4.4496e-01]],\n",
      "\n",
      "         [[-1.6500e-01, -3.7595e-01, -1.1480e-01,  1.0660e+00],\n",
      "          [-2.4347e-01,  3.8786e-01, -8.4753e-01, -7.6839e-02],\n",
      "          [ 1.7897e+00,  8.6862e-01, -1.3892e-01, -6.2417e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.3878e-01, -3.7049e-01,  1.8884e+00, -2.3619e+00],\n",
      "          [-8.0387e-01,  2.5687e-01, -7.2418e-01,  1.1078e-01],\n",
      "          [ 4.5610e-01, -5.4978e-01,  1.2423e+00, -7.2299e-01]],\n",
      "\n",
      "         [[ 1.5842e+00, -5.1898e-01,  1.0901e-01, -2.1579e-01],\n",
      "          [ 7.8062e-01,  5.3130e-01, -6.9257e-01, -1.7900e+00],\n",
      "          [-1.2817e+00,  8.3419e-01, -7.6717e-01,  9.5915e-01]],\n",
      "\n",
      "         [[ 1.1588e+00, -7.5721e-01,  8.3412e-01, -9.9515e-01],\n",
      "          [-4.9557e-01, -1.6926e-01, -1.6859e+00, -7.5714e-02],\n",
      "          [-1.1894e+00,  7.1778e-01,  2.7619e-03, -1.4743e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3130e-01,  5.0705e-02,  9.9487e-01,  1.2643e+00],\n",
      "          [ 7.9777e-01,  7.2703e-01, -6.0574e-01,  1.1533e+00],\n",
      "          [ 5.8386e-01,  9.4517e-01, -2.9419e-01, -2.4178e-01]],\n",
      "\n",
      "         [[ 6.9514e-01,  1.4878e+00,  9.5665e-01, -1.1622e+00],\n",
      "          [ 4.2760e-01, -1.1176e+00,  6.8718e-01, -2.5724e-01],\n",
      "          [ 3.4928e-01,  3.9148e-01,  1.0754e+00, -2.0856e-02]],\n",
      "\n",
      "         [[-7.5321e-01,  8.0586e-01, -8.9668e-01,  1.4243e+00],\n",
      "          [ 5.0083e-01,  1.9421e+00,  6.7629e-04,  9.9250e-01],\n",
      "          [ 5.4630e-01, -2.3622e+00, -1.3221e-01, -1.9328e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.3400e+00,  2.6498e-01, -6.5479e-01,  5.5645e-01],\n",
      "          [ 5.1029e-01,  8.0632e-01, -8.7369e-01, -7.3875e-01],\n",
      "          [-1.8609e+00, -4.2158e-01, -5.8708e-01, -9.8139e-01]],\n",
      "\n",
      "         [[-6.1575e-01,  1.1329e+00, -2.1921e-01, -4.1307e-01],\n",
      "          [ 4.2558e-01,  5.6390e-02,  7.4122e-01, -2.1607e+00],\n",
      "          [ 2.4272e-01, -4.2809e-01, -1.1107e+00, -8.3147e-01]],\n",
      "\n",
      "         [[ 3.5557e-01,  1.8940e-01,  7.0807e-01, -1.1954e+00],\n",
      "          [-1.8713e+00, -2.3520e-01,  4.5173e-01, -3.1817e-01],\n",
      "          [-1.1272e+00,  9.9464e-02,  6.9215e-02, -6.0625e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9943e-01,  1.1836e+00, -1.1618e+00,  1.1827e+00],\n",
      "          [-1.1847e+00, -7.3214e-01, -1.1536e+00,  5.2112e-01],\n",
      "          [ 5.1135e-02,  8.7929e-01,  1.1784e+00,  2.8458e+00]],\n",
      "\n",
      "         [[-1.1757e-01,  1.5655e+00, -5.2024e-01, -6.4849e-01],\n",
      "          [-1.2717e+00, -3.1477e-01,  1.1606e+00, -1.0012e+00],\n",
      "          [-9.1151e-01,  1.5570e+00,  6.2886e-01,  1.3868e+00]],\n",
      "\n",
      "         [[-8.9954e-01,  4.9423e-01,  4.0288e-01,  3.9676e-03],\n",
      "          [ 7.2738e-01, -1.0837e+00, -1.5884e+00, -3.4919e-01],\n",
      "          [-2.2660e-01,  6.0625e-01,  1.0230e+00, -1.4443e+00]]]],\n",
      "       requires_grad=True)\n",
      "torch.int64\n",
      "tensor([[[0, 1, 1, 1],\n",
      "         [1, 1, 1, 2],\n",
      "         [0, 0, 2, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1],\n",
      "         [2, 0, 0, 0],\n",
      "         [1, 1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [1, 0, 0, 0],\n",
      "         [0, 1, 0, 2]],\n",
      "\n",
      "        [[0, 0, 1, 0],\n",
      "         [2, 2, 0, 1],\n",
      "         [0, 0, 2, 1]],\n",
      "\n",
      "        [[1, 0, 2, 1],\n",
      "         [0, 0, 0, 2],\n",
      "         [0, 0, 2, 1]]])\n"
     ]
    }
   ],
   "source": [
    "loss1 = nn.CrossEntropyLoss(ignore_index=1)#类别1不参与计算loss\n",
    "#逐个像素点求loss,输出的loss的size与target一致\n",
    "loss2=nn.CrossEntropyLoss(ignore_index=1,reduction='none')\n",
    "\n",
    "# input, [batch_size=5,num_classes=3,H,W]\n",
    "input = torch.randn(5,3,3,4,requires_grad=True)\n",
    "print(input.dtype)\n",
    "print(input)\n",
    "\n",
    "# target, [batch_size=5,H,W]\n",
    "#target = torch.ones(5,3,4, dtype=torch.long)\n",
    "target=torch.randint(0,3,size=(5,3,4),dtype=torch.long)\n",
    "print(target.dtype)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(1.5094, grad_fn=<NllLoss2DBackward>)\n",
      "tensor([1.5094], grad_fn=<UnsqueezeBackward0>)\n",
      "tensor(1.5094, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "losses = loss1(input, target)\n",
    "\n",
    "#输出是标量的Tensor\n",
    "print(losses.size())\n",
    "print(losses)\n",
    "\n",
    "\n",
    "#标量的Tensor==>矩阵Tensor\n",
    "losses=torch.unsqueeze(losses,0)\n",
    "print(losses)\n",
    "\n",
    "#对矩阵Tensor求平均==>标量的Tensor\n",
    "print(losses.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n",
      "tensor([[[0.9524, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 2.2215],\n",
      "         [2.2144, 3.8839, 1.1215, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.6710, 1.0882, 0.8814, 0.6828],\n",
      "         [0.0000, 0.0000, 0.3532, 0.0000]],\n",
      "\n",
      "        [[1.0213, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 1.5105, 1.8683, 0.7398],\n",
      "         [1.0131, 0.0000, 1.8099, 2.5796]],\n",
      "\n",
      "        [[2.1416, 1.4608, 0.0000, 0.4400],\n",
      "         [3.0803, 1.6433, 2.2815, 0.0000],\n",
      "         [2.4229, 1.3022, 0.6022, 0.0000]],\n",
      "\n",
      "        [[0.0000, 1.0876, 0.4740, 0.0000],\n",
      "         [2.1615, 1.1699, 2.4651, 1.3632],\n",
      "         [0.7605, 1.3165, 1.0446, 0.0000]]], grad_fn=<NllLoss2DBackward>)\n",
      "torch.Size([1, 5, 3, 4])\n",
      "tensor([[[[0.9524, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 2.2215],\n",
      "          [2.2144, 3.8839, 1.1215, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.6710, 1.0882, 0.8814, 0.6828],\n",
      "          [0.0000, 0.0000, 0.3532, 0.0000]],\n",
      "\n",
      "         [[1.0213, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 1.5105, 1.8683, 0.7398],\n",
      "          [1.0131, 0.0000, 1.8099, 2.5796]],\n",
      "\n",
      "         [[2.1416, 1.4608, 0.0000, 0.4400],\n",
      "          [3.0803, 1.6433, 2.2815, 0.0000],\n",
      "          [2.4229, 1.3022, 0.6022, 0.0000]],\n",
      "\n",
      "         [[0.0000, 1.0876, 0.4740, 0.0000],\n",
      "          [2.1615, 1.1699, 2.4651, 1.3632],\n",
      "          [0.7605, 1.3165, 1.0446, 0.0000]]]], grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([])\n",
      "tensor(0.8805, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "losses = loss2(input, target)\n",
    "\n",
    "#输出是矩阵的Tensor，size和target一致\n",
    "#忽略类别的位置loss为0\n",
    "print(losses.size())\n",
    "print(losses)\n",
    "\n",
    "\n",
    "#矩阵的Tensor==>增加1维矩阵Tensor\n",
    "losses=torch.unsqueeze(losses,0)\n",
    "print(losses.size())\n",
    "print(losses)\n",
    "\n",
    "\n",
    "#对矩阵Tensor求平均==>标量的Tensor\n",
    "losses=losses.mean()\n",
    "print(losses.size())\n",
    "print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_label=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 0, 0, 0],\n",
      "          [0, 0, 0, 2],\n",
      "          [0, 0, 2, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 0],\n",
      "          [2, 0, 0, 0],\n",
      "          [0, 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 0],\n",
      "          [0, 0, 0, 0],\n",
      "          [0, 0, 0, 2]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0, 0],\n",
      "          [2, 2, 0, 0],\n",
      "          [0, 0, 2, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 2, 0],\n",
      "          [0, 0, 0, 2],\n",
      "          [0, 0, 2, 0]]]])\n",
      "torch.Size([5, 3, 3, 4])\n",
      "tensor([[[[0.3858, 0.6482, 0.4233, 0.1699],\n",
      "          [0.3109, 0.1289, 0.3991, 0.2552],\n",
      "          [0.1092, 0.0206, 0.1916, 0.1584]],\n",
      "\n",
      "         [[0.4308, 0.1214, 0.4309, 0.2411],\n",
      "          [0.2705, 0.6527, 0.3151, 0.6364],\n",
      "          [0.1767, 0.5242, 0.4826, 0.6265]],\n",
      "\n",
      "         [[0.1834, 0.2304, 0.1458, 0.5890],\n",
      "          [0.4186, 0.2184, 0.2857, 0.1085],\n",
      "          [0.7140, 0.4552, 0.3258, 0.2151]]],\n",
      "\n",
      "\n",
      "        [[[0.0559, 0.3935, 0.6591, 0.0742],\n",
      "          [0.1382, 0.3368, 0.4142, 0.5052],\n",
      "          [0.7306, 0.1171, 0.7024, 0.1460]],\n",
      "\n",
      "         [[0.5709, 0.3392, 0.1112, 0.6347],\n",
      "          [0.6738, 0.4432, 0.4275, 0.0755],\n",
      "          [0.1285, 0.4671, 0.0942, 0.7851]],\n",
      "\n",
      "         [[0.3731, 0.2673, 0.2297, 0.2911],\n",
      "          [0.1881, 0.2200, 0.1583, 0.4193],\n",
      "          [0.1409, 0.4158, 0.2034, 0.0689]]],\n",
      "\n",
      "\n",
      "        [[[0.3601, 0.1363, 0.4732, 0.4421],\n",
      "          [0.4109, 0.2208, 0.1544, 0.4772],\n",
      "          [0.3631, 0.6206, 0.1637, 0.4113]],\n",
      "\n",
      "         [[0.5181, 0.5736, 0.4554, 0.0391],\n",
      "          [0.2838, 0.0349, 0.5625, 0.1164],\n",
      "          [0.2872, 0.3567, 0.6439, 0.5129]],\n",
      "\n",
      "         [[0.1217, 0.2901, 0.0714, 0.5188],\n",
      "          [0.3053, 0.7443, 0.2831, 0.4063],\n",
      "          [0.3497, 0.0227, 0.1925, 0.0758]]],\n",
      "\n",
      "\n",
      "        [[[0.1175, 0.2321, 0.1550, 0.6440],\n",
      "          [0.4972, 0.5478, 0.1021, 0.3618],\n",
      "          [0.0887, 0.2719, 0.2841, 0.2765]],\n",
      "\n",
      "         [[0.2424, 0.5528, 0.2395, 0.2443],\n",
      "          [0.4568, 0.2588, 0.5135, 0.0873],\n",
      "          [0.7267, 0.2702, 0.1683, 0.3212]],\n",
      "\n",
      "         [[0.6402, 0.2152, 0.6055, 0.1117],\n",
      "          [0.0459, 0.1933, 0.3844, 0.5509],\n",
      "          [0.1847, 0.4579, 0.5476, 0.4023]]],\n",
      "\n",
      "\n",
      "        [[[0.5598, 0.3370, 0.1302, 0.6813],\n",
      "          [0.1152, 0.3104, 0.0850, 0.6109],\n",
      "          [0.4674, 0.2681, 0.4110, 0.8025]],\n",
      "\n",
      "         [[0.3020, 0.4938, 0.2473, 0.1091],\n",
      "          [0.1056, 0.4712, 0.8600, 0.1333],\n",
      "          [0.1785, 0.5279, 0.2372, 0.1865]],\n",
      "\n",
      "         [[0.1382, 0.1692, 0.6225, 0.2096],\n",
      "          [0.7793, 0.2184, 0.0550, 0.2558],\n",
      "          [0.3541, 0.2040, 0.3518, 0.0110]]]], grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([5, 1, 3, 4])\n",
      "tensor([[[[0.3858, 0.6482, 0.4233, 0.1699],\n",
      "          [0.3109, 0.1289, 0.3991, 0.1085],\n",
      "          [0.1092, 0.0206, 0.3258, 0.1584]]],\n",
      "\n",
      "\n",
      "        [[[0.0559, 0.3935, 0.6591, 0.0742],\n",
      "          [0.1881, 0.3368, 0.4142, 0.5052],\n",
      "          [0.7306, 0.1171, 0.7024, 0.1460]]],\n",
      "\n",
      "\n",
      "        [[[0.3601, 0.1363, 0.4732, 0.4421],\n",
      "          [0.4109, 0.2208, 0.1544, 0.4772],\n",
      "          [0.3631, 0.6206, 0.1637, 0.0758]]],\n",
      "\n",
      "\n",
      "        [[[0.1175, 0.2321, 0.1550, 0.6440],\n",
      "          [0.0459, 0.1933, 0.1021, 0.3618],\n",
      "          [0.0887, 0.2719, 0.5476, 0.2765]]],\n",
      "\n",
      "\n",
      "        [[[0.5598, 0.3370, 0.6225, 0.6813],\n",
      "          [0.1152, 0.3104, 0.0850, 0.2558],\n",
      "          [0.4674, 0.2681, 0.3518, 0.8025]]]], grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "#[5, 3, 3, 4]\n",
    "pred=F.softmax(input,dim=1)\n",
    "#print(pred.size())\n",
    "\n",
    "#[5*3*4=60]\n",
    "pixel_losses=loss2(input,target).contiguous().view(-1)\n",
    "#print(pixel_losses.size())\n",
    "\n",
    "#获得target中像素不为ignore_label的位置的索引\n",
    "mask = target.contiguous().view(-1) != ignore_label\n",
    "#print(mask)\n",
    "\n",
    "# 将target中像素ignore_label转化为0==>tmp_target\n",
    "tmp_target = target.clone()\n",
    "tmp_target[tmp_target == ignore_label] = 0\n",
    "lll=tmp_target.unsqueeze(1)\n",
    "print(lll)\n",
    "\n",
    "print(pred.size())\n",
    "print(pred)\n",
    "pred = pred.gather(1, lll)\n",
    "print(pred.size())\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35])\n",
      "tensor([0.3858, 0.1085, 0.1092, 0.0206, 0.3258, 0.1881, 0.3368, 0.4142, 0.5052,\n",
      "        0.7024, 0.3601, 0.2208, 0.1544, 0.4772, 0.3631, 0.1637, 0.0758, 0.1175,\n",
      "        0.2321, 0.6440, 0.0459, 0.1933, 0.1021, 0.0887, 0.2719, 0.5476, 0.3370,\n",
      "        0.6225, 0.1152, 0.3104, 0.0850, 0.2558, 0.4674, 0.2681, 0.3518],\n",
      "       grad_fn=<IndexBackward>)\n",
      "torch.Size([35])\n",
      "tensor([0.0206, 0.0459, 0.0758, 0.0850, 0.0887, 0.1021, 0.1085, 0.1092, 0.1152,\n",
      "        0.1175, 0.1544, 0.1637, 0.1881, 0.1933, 0.2208, 0.2321, 0.2558, 0.2681,\n",
      "        0.2719, 0.3104, 0.3258, 0.3368, 0.3370, 0.3518, 0.3601, 0.3631, 0.3858,\n",
      "        0.4142, 0.4674, 0.4772, 0.5052, 0.5476, 0.6225, 0.6440, 0.7024],\n",
      "       grad_fn=<SortBackward>)\n",
      "tensor([ 3, 20, 16, 30, 23, 22,  1,  2, 28, 17, 12, 15,  5, 21, 11, 18, 31, 33,\n",
      "        24, 29,  4,  6, 26, 34, 10, 14,  0,  7, 32, 13,  8, 25, 27, 19,  9])\n"
     ]
    }
   ],
   "source": [
    "pred= pred.contiguous().view(-1,)[mask]\n",
    "print(pred.size())\n",
    "print(pred)\n",
    "\n",
    "pred,ind=pred.contiguous().sort()\n",
    "print(pred.size())\n",
    "print(pred)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.numel() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label#255\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weight, #每个class的加权\n",
    "                                             ignore_index=ignore_label)#指定忽略的 target 值255,不计算loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "        '''\n",
    "\n",
    "        :param score: 模型的输出Tensor:[bs,num_classes,128,256]\n",
    "        :param target: labels Tensor:[bs,512,1024]\n",
    "        :return:\n",
    "        '''\n",
    "        ph, pw = score.size(2), score.size(3)#128,256\n",
    "        h, w = target.size(1), target.size(2)#512,1024\n",
    "        #如果模型输出score大小<label的大小，对score上采样至label大小\n",
    "        if ph != h or pw != w:\n",
    "            score = F.upsample(\n",
    "                    input=score, size=(h, w), mode='bilinear')\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
