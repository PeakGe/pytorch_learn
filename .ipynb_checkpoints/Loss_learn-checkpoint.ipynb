{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CrossEntropyLoss\n",
    "### class torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100, reduce=None, reduction='mean')[source]\n",
    "\n",
    "作用:\n",
    "\n",
    "- 针对单目标分类问题结合了 nn.LogSoftmax() 和 nn.NLLLoss() 来计算 loss.用于训练 C 类别classes 的分类问题.\n",
    "\n",
    "    - 参数 weight 是 1D Tensor, 分别对应每个类别class 的权重. 对于类别不平衡的训练数据集比较有用.\n",
    "\n",
    "    - 输入input 包含了每一类别的概率或score.\n",
    "\n",
    "    - 输入 input Tensor 的大小是 (minibatch,C) 或 (minibatch,C,d1,d2,...,dK). K≥2 表示 K-dim 场景.\n",
    "\n",
    "    - 输入 target 是类别class 的索引([0,C−1], C 是类别classes 总数.)\n",
    "\n",
    "    $loss(score,target)=-log(\\frac{exp(score[target])}{\\sum_{j}^{C}exp(score[j]])})=-score[target]+log(\\sum_{j}^{C}exp(score[j]))$\n",
    "    - 带 weight形式:\n",
    "    \n",
    "    $weight[target](-score[target]+log(\\sum_{j}^{C}exp(score[j])))$\n",
    "    - losses 在 minibatch 内求平均.\n",
    "\n",
    "- 也支持高维输入 inputs, 如 2D images, 则会逐元素计算 NLL Loss.\n",
    "\n",
    "参数：\n",
    "- weight(Tensor, optional) - 每个类别class 的权重. 默认为值为 1 的 Tensor.\n",
    "\n",
    "- size_average(bool, optional) – 默认为 True.\n",
    "\n",
    "    - size_average=True, 则 losses 在 minibatch 结合 weight 求平均average.\n",
    "\n",
    "    - size_average=False, 则losses 在 minibatch 求相加和sum.\n",
    "\n",
    "    - 当 reduce=False 时,忽略该参数.\n",
    "\n",
    "- ignore_index(int, optional) - 指定忽略的 target 值, 不影响 input 梯度计算.\n",
    "\n",
    "    - 当 size_average=True, 对所有非忽略的 targets 求平均.\n",
    "\n",
    "- reduce(bool, optional) - 不推荐使用，默认为 True.\n",
    "\n",
    "    - reduce=True, 则 losses 在 minibatch 求平均或相加和.\n",
    "\n",
    "    - reduce=False, 则 losses 返回 per batch 值, 并忽略 size_average.\n",
    "- reduction(string,optional) - \n",
    "    - reduction='none',逐个像素点求loss,输出的loss的size与target一致\n",
    "    - reduction='mean',默认，输出总和除以输出元素数量(batch_size)\n",
    "    - reduction='sum',输出求和\n",
    "\n",
    "输入:input x, (N,C), C=num_classes 类别总数。输入:target y, (N), 每个值都是 0≤targets[i]≤C−1\n",
    "输出:如果 reduce=True, 输出标量值. 如果 reduce=False, 输出与输入target一致, (N)(N)\n",
    "\n",
    "输入:input x, (N,C,d1,d2,...,dK)(N,C,d1,d2,...,dK), K≥2 适用于 K-dim 场景。输入: target y, (N,d1,d2,...,dK), K≥2适用于 K-dim 场景\n",
    "\n",
    "输出:如果 reduce=True, 输出标量值. 如果 reduce=False, 输出与输入target一致, (N,d1,d2,...,dK), K≥2 适用于 KK-dim 场景\n",
    "\n",
    "**注意：**size_average和reduce正在被弃用，指定size_average和reduction中的任何一个都将覆盖reduce。 默认值：'mean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "loss1 = nn.CrossEntropyLoss()\n",
    "#逐个像素点求loss,输出的loss的size与target一致\n",
    "loss2=nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(0.8765, grad_fn=<NllLoss2DBackward>)\n",
      "tensor([0.8765], grad_fn=<UnsqueezeBackward0>)\n",
      "tensor(0.8765, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# input, [batch_size=5,num_classes=2,H,W]\n",
    "input = torch.randn(5,2,3,4,requires_grad=True)\n",
    "\n",
    "# target, [batch_size=5,H,W]\n",
    "target = torch.ones(5,3,4, dtype=torch.long)\n",
    "losses = loss1(input, target)\n",
    "\n",
    "#输出是标量的Tensor\n",
    "print(losses.size())\n",
    "print(losses)\n",
    "\n",
    "\n",
    "#标量的Tensor==>矩阵Tensor\n",
    "losses=torch.unsqueeze(losses,0)\n",
    "print(losses)\n",
    "\n",
    "#对矩阵Tensor求平均==>标量的Tensor\n",
    "print(losses.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n",
      "tensor([[[2.7048, 0.1123, 0.5359, 0.3774],\n",
      "         [1.6952, 2.1477, 0.6256, 0.0575],\n",
      "         [0.0589, 1.3138, 1.3982, 0.1222]],\n",
      "\n",
      "        [[0.3015, 0.8584, 0.5813, 0.4322],\n",
      "         [1.0937, 0.8110, 0.6381, 0.1653],\n",
      "         [1.3317, 0.7927, 1.2190, 2.3843]],\n",
      "\n",
      "        [[1.9092, 1.0830, 0.4308, 0.4853],\n",
      "         [0.0863, 0.1021, 0.1793, 0.2180],\n",
      "         [0.3895, 0.3439, 0.1253, 1.0049]],\n",
      "\n",
      "        [[0.4686, 1.0624, 0.2343, 0.2983],\n",
      "         [0.5107, 0.8927, 0.3691, 0.0320],\n",
      "         [1.2497, 0.8411, 1.6227, 0.1318]],\n",
      "\n",
      "        [[0.2675, 0.8722, 0.4760, 0.3298],\n",
      "         [0.3781, 0.4217, 2.3875, 1.9081],\n",
      "         [1.4623, 1.5759, 0.3132, 2.7622]]], grad_fn=<NllLoss2DBackward>)\n",
      "torch.Size([1, 5, 3, 4])\n",
      "tensor([[[[2.7048, 0.1123, 0.5359, 0.3774],\n",
      "          [1.6952, 2.1477, 0.6256, 0.0575],\n",
      "          [0.0589, 1.3138, 1.3982, 0.1222]],\n",
      "\n",
      "         [[0.3015, 0.8584, 0.5813, 0.4322],\n",
      "          [1.0937, 0.8110, 0.6381, 0.1653],\n",
      "          [1.3317, 0.7927, 1.2190, 2.3843]],\n",
      "\n",
      "         [[1.9092, 1.0830, 0.4308, 0.4853],\n",
      "          [0.0863, 0.1021, 0.1793, 0.2180],\n",
      "          [0.3895, 0.3439, 0.1253, 1.0049]],\n",
      "\n",
      "         [[0.4686, 1.0624, 0.2343, 0.2983],\n",
      "          [0.5107, 0.8927, 0.3691, 0.0320],\n",
      "          [1.2497, 0.8411, 1.6227, 0.1318]],\n",
      "\n",
      "         [[0.2675, 0.8722, 0.4760, 0.3298],\n",
      "          [0.3781, 0.4217, 2.3875, 1.9081],\n",
      "          [1.4623, 1.5759, 0.3132, 2.7622]]]], grad_fn=<UnsqueezeBackward0>)\n",
      "torch.Size([])\n",
      "tensor(0.8164, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# input, [batch_size=5,num_classes=2,H,W]\n",
    "input = torch.randn(5,2,3,4,requires_grad=True)\n",
    "\n",
    "# target, [batch_size=5,H,W]\n",
    "target = torch.ones(5,3,4, dtype=torch.long)\n",
    "losses = loss2(input, target)\n",
    "\n",
    "#输出是矩阵的Tensor，size和target一致\n",
    "print(losses.size())\n",
    "print(losses)\n",
    "\n",
    "\n",
    "#矩阵的Tensor==>增加1维矩阵Tensor\n",
    "losses=torch.unsqueeze(losses,0)\n",
    "print(losses.size())\n",
    "print(losses)\n",
    "\n",
    "\n",
    "#对矩阵Tensor求平均==>标量的Tensor\n",
    "losses=losses.mean()\n",
    "print(losses.size())\n",
    "print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label#255\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weight, #每个class的加权\n",
    "                                             ignore_index=ignore_label)#指定忽略的 target 值255,不计算loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "        '''\n",
    "\n",
    "        :param score: 模型的输出Tensor:[bs,num_classes,128,256]\n",
    "        :param target: labels Tensor:[bs,512,1024]\n",
    "        :return:\n",
    "        '''\n",
    "        ph, pw = score.size(2), score.size(3)#128,256\n",
    "        h, w = target.size(1), target.size(2)#512,1024\n",
    "        #如果模型输出score大小<label的大小，对score上采样至label大小\n",
    "        if ph != h or pw != w:\n",
    "            score = F.upsample(\n",
    "                    input=score, size=(h, w), mode='bilinear')\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
