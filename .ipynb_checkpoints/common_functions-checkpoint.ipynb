{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view(*args)\n",
    "\n",
    "返回具有相同数据但大小不同的新张量。 返回的张量必须有与原张量相同的数据和相同数量的元素，但可以有不同的大小。一个张量必须是连续contiguous()的才能被查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.view(16)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=x.view(-1,8)\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view_as(tensor)\n",
    "返回被视作与给定的tensor相同大小的原tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "y=torch.randn(2,8)\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "z=x.view_as(y)\n",
    "print(x.size())\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.prod\n",
    "**```torch.prod(input) → float```**\n",
    "\n",
    "返回输入张量input 所有元素的积。\n",
    "\n",
    "参数：input (Tensor) – 输入张量\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(1,13).view(3,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(479001600)\n"
     ]
    }
   ],
   "source": [
    "b=torch.prod(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```torch.prod(input, dim, out=None) → Tensor```**\n",
    "\n",
    "返回输入张量给定维度上每行的积。 输出形状与输入相同，除了给定维度上为1.\n",
    "\n",
    "参数：\n",
    "\n",
    "- input (Tensor) – 输入张量\n",
    "- dim (int) – 缩减的维度\n",
    "- out (Tensor, 可选的) – 结果张量\n",
    "\n",
    "例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.arange(1,13).view(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([   24,  1680, 11880])\n"
     ]
    }
   ],
   "source": [
    "b=torch.prod(a,1)\n",
    "print(b.size())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item()\n",
    "\n",
    "返回此张量的python值。仅适用于具有一个元素的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(720)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(1,7).view(2,3)\n",
    "b=torch.prod(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=b.item()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tolist()\n",
    "\n",
    "将张量作为（嵌套）列表返回。对于标量，返回标准Python数，就像使用item（）一样。\n",
    "\n",
    "如有必要，张量会自动移动到CPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(1,7).view(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "b=a.tolist()\n",
    "c=a[0,0].tolist()\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unsqueeze()\n",
    "#### torch.unsqueeze(input, dim, out=None)\n",
    "返回一个新的张量，**对输入的制定位置插入维度 1**\n",
    "\n",
    "注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。\n",
    "\n",
    "可以使用[-input.dim()-1，input.dim()+1]范围内的dim值。 负dim将对应于在dim = dim + input.dim()+1处应用的unsqueeze（）。\n",
    "参数:\n",
    "\n",
    "- tensor (Tensor) – 输入张量\n",
    "- dim (int) – 插入维度的索引\n",
    "- out (Tensor, 可选的) – 结果张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3,4])\n",
    "print(x.size())\n",
    "y=torch.unsqueeze(x,0)\n",
    "z=torch.unsqueeze(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())\n",
    "print(y)\n",
    "print(z.size())\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
