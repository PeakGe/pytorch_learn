{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class torch.nn.Parameter()\n",
    "一种Variable，被视为一个模块参数。\n",
    "\n",
    "- Parameters 是 Variable 的子类。当与Module一起使用时，它们具有非常特殊的属性，当它们被分配为模块属性时，它们被自动添加到其参数列表中，并将出现在例如parameters()迭代器中。分配变量没有这样的效果。这是因为人们可能希望在模型中缓存一些临时状态，如RNN的最后一个隐藏状态。如果没有这样的班级Parameter，这些临时人员也会注册。\n",
    "\n",
    "- 解释：**在Module中的层在定义时，相关Variable的requires_grad参数默认是True。 在计算图中，如果有一个输入的requires_grad是True，那么输出的requires_grad也是True。只有在所有输入的requires_grad都为False时，输出的requires_grad才为False。**\n",
    "\n",
    "- 另一个区别是，parameters不能是volatile，他们默认要求梯度。\n",
    "\n",
    "- 参数说明:\n",
    "\n",
    "    - data (Tensor) – parameter tensor.\n",
    "\n",
    "    - requires_grad (bool, optional) – 默认True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.分配Tensor时，默认Tensor的requires_grad属性为False，可以设置为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor和Variable已经合并了\n",
    "x=torch.randn((2,3,4))\n",
    "y=torch.randn((4,3,2),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 4])\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(x.size())\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.在Module中的层在定义时，相关Tensor的requires_grad属性默认是True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "    def farward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "# Initialize model\n",
    "model=TheModelClass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1model.parameters()\n",
    "- 迭代model.parameters()将会返回每一次迭代元素的param，**可以用来改变requires_grad的属性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for  param in model.parameters():\n",
    "    print(param.requires_grad)\n",
    "    #修改requires_grad的属性为False\n",
    "    param.requires_grad=False\n",
    "    \n",
    "for  param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2model.named_parameters()\n",
    "- 迭代model.named_parameters()将会返回每一次迭代元素的name和param的元组，**可以用来改变requires_grad的属性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\tTrue\n",
      "conv1.bias\tTrue\n",
      "conv2.weight\tTrue\n",
      "conv2.bias\tTrue\n",
      "fc1.weight\tTrue\n",
      "fc1.bias\tTrue\n",
      "fc2.weight\tTrue\n",
      "fc2.bias\tTrue\n",
      "fc3.weight\tTrue\n",
      "fc3.bias\tTrue\n",
      "conv1.weight\tFalse\n",
      "conv1.bias\tFalse\n",
      "conv2.weight\tFalse\n",
      "conv2.bias\tFalse\n",
      "fc1.weight\tFalse\n",
      "fc1.bias\tFalse\n",
      "fc2.weight\tFalse\n",
      "fc2.bias\tFalse\n",
      "fc3.weight\tFalse\n",
      "fc3.bias\tFalse\n"
     ]
    }
   ],
   "source": [
    "for  name,param in model.named_parameters():\n",
    "    print(name+'\\t'+str(param.requires_grad))\n",
    "    #修改requires_grad的属性为False\n",
    "    param.requires_grad=False\n",
    "    \n",
    "for  name,param in model.named_parameters():\n",
    "    print(name+'\\t'+str(param.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 model.state_dict().items()\n",
    "- 每次迭代model.state_dict().items()会返回所有的name和param，**但是这里的所有的param都是requires_grad=False,没有办法改变requires_grad的属性，所以改变requires_grad的属性只能通过上面的两种方式。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\tFalse\n",
      "conv1.bias\tFalse\n",
      "conv2.weight\tFalse\n",
      "conv2.bias\tFalse\n",
      "fc1.weight\tFalse\n",
      "fc1.bias\tFalse\n",
      "fc2.weight\tFalse\n",
      "fc2.bias\tFalse\n",
      "fc3.weight\tFalse\n",
      "fc3.bias\tFalse\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.state_dict().items():\n",
    "    print(name+'\\t'+str(param.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 改变了requires_grad之后要修改optimizer的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d90372f7b13b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer = optim.SGD(\n\u001b[0;32m      2\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m#只更新requires_grad=True的参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m             \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMOMENTUM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(\n",
    "            parameters=filter(lambda p: p.requires_grad, model.parameters()),   #只更新requires_grad=True的参数\n",
    "            lr=cfg.TRAIN.LR,\n",
    "            momentum=cfg.TRAIN.MOMENTUM,\n",
    "            weight_decay=cfg.TRAIN.WD,\n",
    "            nesterov=cfg.TRAIN.NESTEROV\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
